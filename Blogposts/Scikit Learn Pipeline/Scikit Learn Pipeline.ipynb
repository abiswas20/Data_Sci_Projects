{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Building Pipelines and Using Grid Searches in Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several steps to building even a basic machine learning model. Before any new data can be fed to a model, features have to be selected, data needs to be standardized and the exact type estimator to be used have to be selected and fit to training data. On top of all that, building models involve two types of parameters:  \n",
    "i) **model parameters**: configuration variables internal to the model and which can be estimated from data; and,  \n",
    "ii) **model hyperparameters**: configuration variables external to the model and cannot be estimated from data.[[1]](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/)  \n",
    "Hyperparameters must be supplied externally and adjusting them is a large part of developing a model. This process is often also referred to as hyperparameter tuning and involves the data scientist optimizing such parameters for performance. Throughout the model building process there are many steps where it is necessary to provide hyperparameters. \n",
    "\n",
    "Building a model is an iterative process. And as one would imagine, the process can easily become tedious, unwieldy and error-prone. Thankfully Scikit-Learn has a great set of tools meant to address exactly this: pipeline and gridsearch. This goal of this article is to demonstrate the usage of these tools. Before we forward it's important to mention, however, that the rest of the article is not a exercise in regression analysis. The analytical work here is simply a vehicle to demonstrate the Scikit learn tools. With that out of the way, let's get started. As always we start by importing the necessary libraries. As for libraries relevant to the subject of this article: we need ```make_pipeline``` from ```sklearn.pipeline``` to create a pipeline. The ```GridSearchCV``` method comes from ```model_selection``` module in Scikit-Learn library. We will use the Penguins dataset that ships with Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user-1131/venv/lib/python3.6/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins=sns.load_dataset('penguins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "penguins.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the process of building a pipeline, I'll use regression to estimate body mass, which is a continuous numeric variable. Let's choose 3 columns with numerical data (```bill length```, ```bill depth```, ```flipper length```) and 1 with categorical variable (```sex```) as features. We don't need to include ```species``` as the other features already encapsulates that information. The ```sex``` column has some null values and we'll drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a feature matrix (**X**) and a matrix with target variable (**y**). Since ```sex``` is a categorical variable, we'll also need to dummify them before splitting the matrices into training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=penguins.drop(['island','body_mass_g'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     sex\n",
       "0    Adelie    MALE\n",
       "1    Adelie  FEMALE\n",
       "2    Adelie  FEMALE\n",
       "4    Adelie  FEMALE\n",
       "5    Adelie    MALE\n",
       "..      ...     ...\n",
       "338  Gentoo  FEMALE\n",
       "340  Gentoo  FEMALE\n",
       "341  Gentoo    MALE\n",
       "342  Gentoo  FEMALE\n",
       "343  Gentoo    MALE\n",
       "\n",
       "[333 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['species','sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pass 'species' column to OneHotEncoder\n",
    "X=pd.get_dummies(data=X,columns=['species','sex'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=penguins['body_mass_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>species_Chinstrap</th>\n",
       "      <th>species_Gentoo</th>\n",
       "      <th>sex_MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>49.8</td>\n",
       "      <td>16.8</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>40.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bill_length_mm  bill_depth_mm  flipper_length_mm  species_Chinstrap  \\\n",
       "285            49.8           16.8              230.0                  0   \n",
       "29             40.5           18.9              180.0                  0   \n",
       "\n",
       "     species_Gentoo  sex_MALE  \n",
       "285               1         1  \n",
       "29                0         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to set-up a pipeline and build a model. The ```pipeline``` module in Scikit-Learn has a ```make-pipeline``` method. The first step is to to instantiate the method. We do this by passing the steps we want input data to go through in order. Once instantiated the pipeline works just like any other Scikit-Learn estimator. Here we are building a new pipeline and naming it pipe. The methods specified within ```make_pipeline``` from left to right are:  \n",
    "i) ```StandardScaler()```-> We have not standardized the data before ```train_test_split```. So incoming data needs to standardized before any other transformation is performed on it.  \n",
    "ii) ```SelectKBest()``` -> This method comes from ```feature_selection``` module of Scikit-learn. It selects the best features based on a scoring function (in this case, ```f_regression)```. The number of features is specified by the value of parameter ```k```. We want to try different number of features and find what works best in terms of performance. We can do that in the ```GridSearchCV``` process and will come back to it shortly.  \n",
    "iii)```Ridge()``` -> This is an estimator that performs the actual regression. The name of the method refers to Tikhonov regularization (more commonly known as ridge regression) performed to reduce the effect of multicollinearity. Like the parameter k discussed previously, we want to test several different values for the various parameters of ridge regression. We do that as part of a grid search, as we discuss next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=make_pipeline(StandardScaler(),SelectKBest(f_regression),Ridge())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline is now ready to be fitted. Like previously mentioned, pipeline acts just like any other estimator. It can accept parameters for every method that is part of the pipeline. A quick way to get a list of parameters that a pipeline can accept is show below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'selectkbest', 'ridge', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'selectkbest__k', 'selectkbest__score_func', 'ridge__alpha', 'ridge__copy_X', 'ridge__fit_intercept', 'ridge__max_iter', 'ridge__normalize', 'ridge__random_state', 'ridge__solver', 'ridge__tol'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search gives us the ability to search over specified values for each of the parameters listed above. We do this by creating a dictionary with names of parameters as keys and lists of parameter settings to try as values. In our example we call this dictionary ```params``` and pass it ```GridSearchCV```. Notice the parameter n_jobs. It tells Scikit-learn how many jobs to run in parallel. Setting to -1 is equivalent to instructing Scikit-learn to use all processors. Once fitted, the ```GridSearchCV``` instance ```gs``` acts just like any other estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'selectkbest__k':[1,2,3,4,5,6],\n",
    "    'ridge__fit_intercept':[True,False],\n",
    "    'ridge__alpha':[0.0001,0.001,0.01,0.1,1,10,100,1000],\n",
    "    'ridge__solver':[ 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=GridSearchCV(pipe,params,n_jobs=-1,cv=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('selectkbest',\n",
       "                                        SelectKBest(score_func=<function f_regression at 0x7f03b0bf2d08>)),\n",
       "                                       ('ridge', Ridge())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'ridge__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                          1000],\n",
       "                         'ridge__fit_intercept': [True, False],\n",
       "                         'ridge__solver': ['svd', 'cholesky', 'lsqr',\n",
       "                                           'sparse_cg', 'sag', 'saga'],\n",
       "                         'selectkbest__k': [1, 2, 3, 4, 5, 6]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of searching over all the permutations of the selected parameters, GridSearchCV performs cross-validation on training data. The default value is 5 times but we can specify any other number using the parameter ```cv```. The attribute ```cv_results_``` includes detailed results for each cross-validation run and provides a wealth of data that can be used to determine the fit and robustness of the model. Details of the permutation of parameters that performs the best is provided by the ```best_params_``` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>{'ridge__alpha': 1, 'ridge__fit_intercept': Tr...</td>\n",
       "      <td>0.880676</td>\n",
       "      <td>0.803462</td>\n",
       "      <td>0.836905</td>\n",
       "      <td>0.898847</td>\n",
       "      <td>0.854736</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>0.033363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>{'ridge__alpha': 1, 'ridge__fit_intercept': Tr...</td>\n",
       "      <td>0.880632</td>\n",
       "      <td>0.803406</td>\n",
       "      <td>0.836768</td>\n",
       "      <td>0.898888</td>\n",
       "      <td>0.854679</td>\n",
       "      <td>0.854875</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>{'ridge__alpha': 1, 'ridge__fit_intercept': Tr...</td>\n",
       "      <td>0.880632</td>\n",
       "      <td>0.803406</td>\n",
       "      <td>0.836768</td>\n",
       "      <td>0.898888</td>\n",
       "      <td>0.854679</td>\n",
       "      <td>0.854875</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>{'ridge__alpha': 1, 'ridge__fit_intercept': Tr...</td>\n",
       "      <td>0.880632</td>\n",
       "      <td>0.803406</td>\n",
       "      <td>0.836768</td>\n",
       "      <td>0.898888</td>\n",
       "      <td>0.854679</td>\n",
       "      <td>0.854875</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>{'ridge__alpha': 1, 'ridge__fit_intercept': Tr...</td>\n",
       "      <td>0.880620</td>\n",
       "      <td>0.803301</td>\n",
       "      <td>0.836758</td>\n",
       "      <td>0.898909</td>\n",
       "      <td>0.854733</td>\n",
       "      <td>0.854864</td>\n",
       "      <td>0.033436</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  split0_test_score  \\\n",
       "317  {'ridge__alpha': 1, 'ridge__fit_intercept': Tr...           0.880676   \n",
       "299  {'ridge__alpha': 1, 'ridge__fit_intercept': Tr...           0.880632   \n",
       "293  {'ridge__alpha': 1, 'ridge__fit_intercept': Tr...           0.880632   \n",
       "305  {'ridge__alpha': 1, 'ridge__fit_intercept': Tr...           0.880632   \n",
       "323  {'ridge__alpha': 1, 'ridge__fit_intercept': Tr...           0.880620   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "317           0.803462           0.836905           0.898847   \n",
       "299           0.803406           0.836768           0.898888   \n",
       "293           0.803406           0.836768           0.898888   \n",
       "305           0.803406           0.836768           0.898888   \n",
       "323           0.803301           0.836758           0.898909   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "317           0.854736         0.854925        0.033363                1  \n",
       "299           0.854679         0.854875        0.033399                2  \n",
       "293           0.854679         0.854875        0.033399                2  \n",
       "305           0.854679         0.854875        0.033399                4  \n",
       "323           0.854733         0.854864        0.033436                5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_scores=pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')\n",
    "df_cv_scores[['params','split0_test_score', 'split1_test_score', 'split2_test_score',\\\n",
    "       'split3_test_score', 'split4_test_score', 'mean_test_score',\\\n",
    "       'std_test_score', 'rank_test_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge__alpha': 1,\n",
       " 'ridge__fit_intercept': True,\n",
       " 'ridge__solver': 'sag',\n",
       " 'selectkbest__k': 6}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can predict target values from test set by passing it's feature matrix to ```gs```. Comparing predictions with actual target values is a very effective way of visualizing and communicating performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9089492595461265"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,y_preds);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
